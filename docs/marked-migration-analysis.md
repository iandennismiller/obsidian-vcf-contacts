# Marked Library Migration Analysis

## Executive Summary

This document analyzes the `/src/models` directory to identify opportunities for refactoring markdown parsing code by leveraging the `marked` library. The analysis identifies methods that can be replaced, classes that can be simplified, and constants that should be centralized.

**Key Findings:**
- **~94 regex operations** in contactNote models could be simplified with marked
- **~4,494 lines of code** in contactNote models, with significant markdown parsing overhead
- **Multiple repeated string constants** for markdown headers and sections
- **Heading detection logic** duplicated across multiple classes
- **Section extraction patterns** that could leverage marked's token system

---

## 1. Methods That Can Be Completely Replaced by Marked

### 1.1 Heading Detection and Section Extraction

**Current Implementation:**

The codebase currently uses custom regex patterns for heading detection:

#### In `markdownOperations.ts`:
```typescript
// Line 210: Extract sections using regex
const sectionRegex = /#### ([^\n]+)\n([\s\S]*?)(?=\n#### |$)/g;

// Line 226: Update section using regex
const sectionRegex = new RegExp(`#### ${sectionName}\\n[\\s\\S]*?(?=\\n#### |$)`, 'g');
```

#### In `contactSectionOperations.ts`:
```typescript
// Line 130-131: Case-insensitive, depth-agnostic heading match
// Matches any heading level (##, ###, ####, etc.) with "Contact" in any case
const contactSectionMatch = content.match(/(^|\n)(#{2,})\s*contact\s*\n([\s\S]*?)(?=\n#{2,}\s|\n\n(?:#|$)|\n$)/i);
```

#### In `relationshipOperations.ts`:
```typescript
// Line 35-36: Related section detection
// Matches any heading level (##, ###, ####, etc.) with "Related" in any case
const relatedSectionMatch = content.match(/(^|\n)(#{2,})\s*related\s*\n([\s\S]*?)(?=\n#{2,}\s|\n\n(?:#|$)|\n$)/i);
```

**Marked Library Replacement:**

The `marked` library provides a lexer/tokenizer that can parse markdown into a token tree:

```typescript
import { marked } from 'marked';

// Parse markdown into tokens
const tokens = marked.lexer(content);

// Extract heading tokens
const headings = tokens.filter(token => token.type === 'heading');

// Extract sections (heading + following content)
function extractSections(tokens) {
  const sections = new Map();
  let currentSection = null;
  let currentContent = [];
  
  for (const token of tokens) {
    if (token.type === 'heading') {
      if (currentSection) {
        sections.set(currentSection, currentContent);
      }
      currentSection = token.text;
      currentContent = [];
    } else {
      currentContent.push(token);
    }
  }
  
  if (currentSection) {
    sections.set(currentSection, currentContent);
  }
  
  return sections;
}
```

**Benefits:**
- Eliminates complex regex patterns
- Handles edge cases (varying whitespace, line breaks, heading levels)
- More maintainable and testable
- Follows markdown standards (CommonMark/GFM)

### 1.2 List Parsing

**Current Implementation:**

Multiple locations parse list items manually:

#### In `relationshipOperations.ts`:
```typescript
// Lines 48-98: Manual list parsing with multiple regex patterns
const match1 = line.match(/^-\s*(\w+)\s+\[\[([^\]]+)\]\]/); // type [[Name]]
const match2 = line.match(/^-\s*([^:]+):\s*\[\[([^\]]+)\]\]/); // type: [[Name]]
const match3 = line.match(/^-\s*\[\[([^\]]+)\]\]\s*\(([^)]+)\)/); // [[Name]] (type)
const match4 = line.match(/^-\s*([^:]+):\s*(.+)$/); // type: Name
```

#### In `contactSectionOperations.ts`:
```typescript
// Lines 176-220: Complex list parsing with multiple format detection
const colonMatch = line.match(/^-?\s*([^:]+):\s*(.+)$/);
const spaceMatch = line.match(/^([A-Za-z]+)\s+(.+)$/);
const simpleMatch = line.match(/^-\s*(.+)$/);
```

**Marked Library Replacement:**

```typescript
import { marked } from 'marked';

// Parse list items
const tokens = marked.lexer(content);
const lists = tokens.filter(token => token.type === 'list');

for (const list of lists) {
  for (const item of list.items) {
    const itemText = item.text; // Clean text without list marker
    // Now apply domain-specific parsing (wiki-links, contact data)
  }
}
```

**Benefits:**
- Removes list marker detection code (`-`, `*`, `1.`, etc.)
- Handles nested lists automatically
- Normalizes whitespace
- Reduces code complexity

### 1.3 Whitespace and Line Break Normalization

**Current Implementation:**

Manual string manipulation for whitespace:

```typescript
// In contactSectionOperations.ts, line 137
const lines = contactContent.split('\n');
for (let i = 0; i < lines.length; i++) {
  const line = lines[i].trim();
  if (!line) continue;
  // ...
}
```

**Marked Library Replacement:**

Marked handles whitespace normalization automatically. Tokens provide clean text:

```typescript
const tokens = marked.lexer(content);
// Tokens already have normalized whitespace
```

---

## 2. Opportunities to Remove or Merge Classes

### 2.1 Consider Merging Markdown-Related Operations

**Current Structure:**

- `markdownOperations.ts` (247 lines) - General markdown operations
- `contactSectionOperations.ts` (734 lines) - Contact section specific
- `relationshipOperations.ts` - Related section specific

**Recommendation:**

These classes could be consolidated into a single `MarkdownParsingService` that:
- Uses marked for all structural parsing
- Delegates domain-specific logic to specialized parsers
- Reduces duplication of heading/section detection

**Potential Structure:**
```typescript
class MarkdownParsingService {
  private marked: Marked;
  
  // Generic section operations
  extractSection(sectionName: string): string
  updateSection(sectionName: string, content: string): void
  getSections(): Map<string, Section>
  
  // Delegate to domain-specific parsers
  parseContactSection(): ContactField[]
  parseRelatedSection(): Relationship[]
}

class ContactFieldParser {
  parse(tokens: Token[]): ContactField[]
}

class RelationshipParser {
  parse(tokens: Token[]): Relationship[]
}
```

### 2.2 Remove Custom Section Extraction Utilities

**Current Code Can Be Removed:**

The following methods duplicate functionality:
- `extractMarkdownSections()` in markdownOperations.ts (lines 205-219)
- Contact section regex in contactSectionOperations.ts (lines 130-139)
- Related section regex in relationshipOperations.ts (lines 36-40)

**Replacement:**

Single utility using marked:
```typescript
function extractSection(content: string, sectionName: string): string | null {
  const tokens = marked.lexer(content);
  const sections = groupTokensByHeading(tokens);
  return sections.get(sectionName.toLowerCase());
}
```

---

## 3. Repeated Strings and Constants to Centralize

### 3.1 Markdown Heading Patterns

**Duplicated Across Files:**

```typescript
// markdownOperations.ts, line 46
return `---\n${stringifyYaml(frontmatter)}---\n#### Notes\n${myNote}\n${relatedSection}\n\n${hashtags} ${additionalTags}\n`;

// markdownOperations.ts, line 153
return '## Related\n';

// markdownOperations.ts, line 156
return `## Related\n${relatedEntries.join('\n')}\n`;

// markdownOperations.ts, line 210
const sectionRegex = /#### ([^\n]+)\n([\s\S]*?)(?=\n#### |$)/g;

// markdownOperations.ts, line 228
const newSection = `#### ${sectionName}\n${newContent}`;

// contactSectionOperations.ts, line 393
if (trimmedResult === '## Contact' || trimmedResult === '') {

// contactSectionOperations.ts, line 395
const contactSectionMatch = content.match(/(^|\n)(#{2,})\s*contact\s*\n([\s\S]*?)(?=\n#{2,}\s|\n\n(?:#|$)|\n$)/i);

// relationshipOperations.ts, line 366
let newRelatedSection = '## Related\n';
```

**Recommended Constants File:**

Create `/src/models/contactNote/markdownConstants.ts`:

```typescript
/**
 * Centralized markdown-related constants for contact notes
 */

// Section names
export const SECTION_NAMES = {
  NOTES: 'Notes',
  RELATED: 'Related',
  CONTACT: 'Contact',
} as const;

// Heading levels
export const HEADING_LEVELS = {
  SECTION: '##',    // Main sections like Contact, Related
  SUBSECTION: '####', // Sub-sections like Notes
} as const;

// Section templates
export const SECTION_TEMPLATES = {
  NOTES: (level: string, name: string) => `${level} ${name}\n`,
  RELATED: (level: string, name: string) => `${level} ${name}\n`,
  CONTACT: (level: string, name: string) => `${level} ${name}\n`,
} as const;

// List formats
export const LIST_FORMATS = {
  UNORDERED: '-',
  ORDERED: (n: number) => `${n}.`,
} as const;

// Frontmatter delimiters
export const FRONTMATTER = {
  DELIMITER: '---',
  START: '---\n',
  END: '\n---\n',
} as const;

// Common patterns
export const PATTERNS = {
  WIKI_LINK: /\[\[([^\]]+)\]\]/g,
  HASHTAG: /#\w+/g,
} as const;
```

### 3.2 Regex Patterns

**Duplicated Patterns:**

```typescript
// Heading detection - appears 3+ times with variations
/(^|\n)(#{2,})\s*contact\s*\n/i
/(^|\n)(#{2,})\s*related\s*\n/i
/#### ([^\n]+)\n([\s\S]*?)(?=\n#### |$)/g

// Section content extraction - appears 3+ times
/([\s\S]*?)(?=\n#{2,}\s|\n\n(?:#|$)|\n$)/

// List item patterns - appears 5+ times
/^-\s*(.+)$/
/^-?\s*([^:]+):\s*(.+)$/

// Wiki-link patterns - appears 4+ times
/\[\[([^\]]+)\]\]/
/^-\s*(\w+)\s+\[\[([^\]]+)\]\]/
```

**Recommended Constants:**

```typescript
/**
 * Regex patterns for markdown parsing
 * Note: These are for Obsidian-specific syntax (wiki-links)
 * Standard markdown should use the marked library
 */

export const REGEX_PATTERNS = {
  // Obsidian-specific patterns (not handled by marked)
  WIKI_LINK: /\[\[([^\]]+)\]\]/,
  WIKI_LINK_GLOBAL: /\[\[([^\]]+)\]\]/g,
  
  // Relationship formats (Obsidian-specific)
  RELATIONSHIP_FORMATS: {
    TYPE_LINK: /^-\s*(\w+)\s+\[\[([^\]]+)\]\]/, // type [[Name]]
    TYPE_COLON_LINK: /^-\s*([^:]+):\s*\[\[([^\]]+)\]\]/, // type: [[Name]]
    LINK_TYPE_PARENS: /^-\s*\[\[([^\]]+)\]\]\s*\(([^)]+)\)/, // [[Name]] (type)
    TYPE_COLON_TEXT: /^-\s*([^:]+):\s*(.+)$/, // type: Name
  },
  
  // Field parsing (domain-specific, not standard markdown)
  FIELD_FORMATS: {
    LABEL_COLON_VALUE: /^-?\s*([^:]+):\s*(.+)$/,
    LABEL_SPACE_VALUE: /^([A-Za-z]+)\s+(.+)$/,
    LIST_ITEM: /^-\s*(.+)$/,
  },
} as const;
```

### 3.3 Field Type Constants

**Duplicated Field Types:**

```typescript
// contactSectionOperations.ts, lines 70-77
const DEFAULT_TEMPLATES: Record<string, FuzzyTemplate> = {
  EMAIL: { ... },
  TEL: { ... },
  URL: { ... },
  ADR: { ... }
};

// markdownOperations.ts, lines 52-56
const nameKeys = ["N", "FN"];
const priorityKeys = ["EMAIL", "TEL", "BDAY", "URL", "ORG", "TITLE", "ROLE", "PHOTO", "RELATED", "GENDER"];
const addressKeys = ["ADR"];

// fieldPatternDetection.ts (implied)
// Email, phone, URL, address detection
```

**Recommended Constants:**

```typescript
/**
 * VCard field type constants
 */

export const VCARD_FIELD_TYPES = {
  // Contact fields
  EMAIL: 'EMAIL',
  TEL: 'TEL',
  URL: 'URL',
  ADR: 'ADR',
  
  // Name fields
  N: 'N',
  FN: 'FN',
  
  // Organization fields
  ORG: 'ORG',
  TITLE: 'TITLE',
  ROLE: 'ROLE',
  
  // Other fields
  BDAY: 'BDAY',
  PHOTO: 'PHOTO',
  GENDER: 'GENDER',
  RELATED: 'RELATED',
  UID: 'UID',
  VERSION: 'VERSION',
  NOTE: 'NOTE',
  CATEGORIES: 'CATEGORIES',
} as const;

export const FIELD_GROUPS = {
  NAME: ['N', 'FN'],
  PRIORITY: ['EMAIL', 'TEL', 'BDAY', 'URL', 'ORG', 'TITLE', 'ROLE', 'PHOTO', 'RELATED', 'GENDER'],
  ADDRESS: ['ADR'],
  CONTACT: ['EMAIL', 'TEL', 'URL', 'ADR'],
} as const;

export const FIELD_DISPLAY = {
  EMAIL: { icon: 'ðŸ“§', name: 'Email' },
  TEL: { icon: 'ðŸ“ž', name: 'Phone' },
  URL: { icon: 'ðŸŒ', name: 'Website' },
  ADR: { icon: 'ðŸ ', name: 'Address' },
} as const;
```

---

## 4. Tests That Can Be Removed or Simplified

### 4.1 Markdown Parsing Edge Cases

**Tests that could be removed after migration to marked:**

#### In `markdownOperations.spec.ts`:
- Tests for heading detection edge cases (whitespace variations)
- Tests for section extraction with different heading levels
- Tests for line break normalization

**Current Tests (lines 229-285):**
```typescript
describe('extractMarkdownSections', () => {
  it('should extract sections from markdown content', async () => {
    const content = `---\nFN: John Doe\n---\n#### Notes\nThis is a note.\n\n#### Related\n- spouse [[Jane Doe]]\n...`;
    // Tests custom regex-based section extraction
  });
  
  it('should handle sections with multiple paragraphs', async () => {
    // Tests paragraph handling that marked would handle automatically
  });
  
  it('should handle sections with varying amounts of whitespace', async () => {
    // Tests whitespace handling that marked would handle automatically
  });
});
```

**After Migration:**
These tests should be replaced with simpler integration tests that verify the marked integration works correctly, not testing markdown parsing edge cases (which are tested by marked itself).

#### In `contactSectionOperations.spec.ts`:
- Tests for list item parsing with different markers
- Tests for whitespace handling in lists
- Tests for nested list structures

#### In `relationshipOperations.spec.ts`:
- Tests for relationship list format variations
- Tests for heading level variations

### 4.2 Tests to Keep (Domain-Specific Logic)

These tests should be **preserved** as they test domain logic, not markdown parsing:

- **Contact field detection** (email, phone, URL patterns) - domain-specific
- **Wiki-link extraction** - Obsidian-specific, not standard markdown
- **Relationship type parsing** - domain-specific
- **Gender-aware relationship terms** - domain-specific
- **VCard field mapping** - domain-specific

### 4.3 Helper Functions in Tests to Remove

**In `tests/stories/curatorPipelineIntegration.spec.ts`:**

Lines 120-181 contain manual frontmatter and section extraction:

```typescript
/**
 * Helper function to extract frontmatter from content
 */
function extractFrontmatter(content: string): Record<string, any> {
  const frontmatterMatch = content.match(/^---\n([\s\S]*?)\n---/);
  // Manual YAML parsing...
}

/**
 * Helper function to extract Related section from content
 */
function extractRelatedSection(content: string): string[] {
  const relatedMatch = content.match(/#### Related\n([\s\S]*?)(?:\n#{2,}|\n\n#|$)/i);
  // Manual list parsing...
}
```

**Recommendation:**
After migration, these helpers could use marked-based extraction utilities, reducing duplication and improving reliability.

---

## 5. Refactoring Plan

### Phase 1: Add Marked Dependency and Create Utilities

1. **Add marked to package.json** (if not already present)
   ```json
   {
     "dependencies": {
       "marked": "^12.0.0"
     }
   }
   ```

2. **Create marked utilities** (`src/models/contactNote/markedUtils.ts`)
   - Section extraction using marked tokens
   - Heading detection using marked tokens
   - List item extraction using marked tokens

3. **Create constants file** (`src/models/contactNote/markdownConstants.ts`)
   - Section names, heading levels
   - Field types and display info
   - Obsidian-specific patterns (wiki-links)

### Phase 2: Refactor Core Operations

1. **Update `markdownOperations.ts`**
   - Replace `extractMarkdownSections()` with marked-based implementation
   - Replace `updateMarkdownSection()` to use marked for parsing
   - Keep domain-specific logic (VCard rendering)

2. **Update `contactSectionOperations.ts`**
   - Replace heading detection with marked
   - Replace list parsing with marked
   - Keep domain-specific field detection

3. **Update `relationshipOperations.ts`**
   - Replace heading detection with marked
   - Replace list parsing with marked
   - Keep wiki-link and relationship type parsing

### Phase 3: Update Tests

1. **Remove markdown parsing edge case tests**
   - Whitespace handling
   - Heading level variations
   - List marker variations

2. **Add integration tests for marked usage**
   - Verify marked correctly extracts sections
   - Verify domain logic still works

3. **Update test helpers**
   - Use marked-based extraction
   - Reduce duplication

### Phase 4: Documentation

1. **Update development docs** to reflect marked usage
2. **Document which markdown parsing is delegated to marked**
3. **Document Obsidian-specific patterns still handled manually**

---

## 6. Code Metrics

### Current State

- **Total files in `/src/models`:** 38
- **Lines of code in `/src/models/contactNote`:** 4,494
- **Regex operations in contactNote:** ~94
- **Failing tests (baseline):** 16 failed, 1225 passed

### Expected Impact

**Lines of Code Reduction:**
- Estimated **200-300 lines** of regex-based parsing code can be removed
- Estimated **100-150 lines** of whitespace/normalization code can be removed
- Total reduction: **~300-450 lines** (6-10% of contactNote code)

**Test Reduction:**
- Estimated **20-30** markdown edge case tests can be removed
- These will be replaced by **5-10** integration tests for marked usage
- Net reduction: **15-20 tests**

**Maintainability Improvement:**
- Fewer custom regex patterns to maintain
- Better standards compliance (CommonMark/GFM)
- Reduced edge case handling
- More focused domain logic

---

## 7. Risks and Considerations

### 7.1 Migration Risks

1. **Breaking Changes**
   - Marked may parse some edge cases differently than current regex
   - Need thorough testing of existing content

2. **Performance**
   - Marked adds dependency overhead
   - Need to benchmark on large files
   - Consider caching parsed tokens

3. **Obsidian-Specific Syntax**
   - Wiki-links (`[[Contact]]`) must still be handled manually
   - Marked doesn't understand Obsidian's extensions
   - Need to preserve custom parsing for Obsidian features

### 7.2 Compatibility Considerations

1. **Existing Content**
   - All existing contact notes must continue to work
   - Need migration tests with real user data
   - Consider backward compatibility mode

2. **Plugin Dependencies**
   - Ensure marked doesn't conflict with Obsidian API
   - Test in Obsidian environment, not just unit tests

3. **Future Extensibility**
   - Marked can be extended with custom renderers/tokenizers
   - Plan for future Obsidian feature support

---

## 8. Recommendations

### Immediate Actions

1. **Create proof of concept** with marked for one operation (e.g., section extraction)
2. **Benchmark performance** on representative contact files
3. **Test compatibility** with existing contact notes in demo data
4. **Create constants file** to consolidate repeated strings

### Long-term Strategy

1. **Gradual migration** - one class at a time
2. **Maintain backward compatibility** during transition
3. **Focus on high-value refactorings** - section extraction, heading detection
4. **Keep domain logic separate** - clear separation between markdown parsing and contact logic

### Success Criteria

- [ ] All existing tests pass (except those explicitly testing edge cases now handled by marked)
- [ ] Code reduction of at least 300 lines
- [ ] No performance degradation on large files
- [ ] All existing contact notes parse correctly
- [ ] Improved maintainability metrics (reduced complexity)

---

## Appendix A: Marked Library Capabilities

### What Marked Handles

- **Headings:** Detection and hierarchy (`#`, `##`, `###`, etc.)
- **Lists:** Unordered, ordered, nested structures
- **Paragraphs:** Block-level element parsing
- **Whitespace:** Normalization and trimming
- **Line breaks:** Cross-platform line ending handling
- **Inline elements:** Bold, italic, code, links

### What Marked Does NOT Handle

- **Obsidian wiki-links:** `[[Contact Name]]` syntax
- **Obsidian tags:** `#tag` syntax (though standard markdown also uses `#` for headings)
- **Frontmatter:** YAML frontmatter parsing (use existing Obsidian API)
- **Domain semantics:** Email/phone/URL detection, relationship types

### Marked Extensions Available

- **GFM Heading ID:** For heading anchors
- **Custom Heading ID:** For custom heading IDs
- **More Lists:** Alphabetical and roman numeral lists
- **Extended Tables:** Advanced table features

---

## Appendix B: Code Examples

### Example 1: Current vs. Marked Section Extraction

**Current Implementation (markdownOperations.ts):**
```typescript
async extractMarkdownSections(): Promise<Map<string, string>> {
  const content = await this.contactData.getContent();
  const sections = new Map<string, string>();

  // Split content into sections based on headers
  const sectionRegex = /#### ([^\n]+)\n([\s\S]*?)(?=\n#### |$)/g;
  let match;

  while ((match = sectionRegex.exec(content)) !== null) {
    const [, sectionName, sectionContent] = match;
    sections.set(sectionName.trim(), sectionContent.trim());
  }

  return sections;
}
```

**Marked Implementation:**
```typescript
import { marked } from 'marked';

async extractMarkdownSections(): Promise<Map<string, string>> {
  const content = await this.contactData.getContent();
  const sections = new Map<string, string>();
  
  // Skip frontmatter
  const contentWithoutFrontmatter = content.replace(/^---\n[\s\S]*?\n---\n/, '');
  
  // Parse into tokens
  const tokens = marked.lexer(contentWithoutFrontmatter);
  
  let currentSection: string | null = null;
  let currentContent: marked.Token[] = [];
  
  for (const token of tokens) {
    if (token.type === 'heading' && token.depth === 4) {
      // Save previous section
      if (currentSection !== null) {
        const html = marked.parser(currentContent);
        sections.set(currentSection, html);
      }
      // Start new section
      currentSection = token.text;
      currentContent = [];
    } else if (currentSection !== null) {
      currentContent.push(token);
    }
  }
  
  // Save last section
  if (currentSection !== null) {
    const html = marked.parser(currentContent);
    sections.set(currentSection, html);
  }
  
  return sections;
}
```

**Benefits:**
- No complex regex
- Handles all heading levels
- Automatically handles whitespace
- Can easily extend to different heading depths

### Example 2: Current vs. Marked List Extraction

**Current Implementation (relationshipOperations.ts):**
```typescript
const lines = relatedContent.split('\n').filter(line => line.trim());

for (const line of lines) {
  // Parse different formats:
  const match1 = line.match(/^-\s*(\w+)\s+\[\[([^\]]+)\]\]/);
  const match2 = line.match(/^-\s*([^:]+):\s*\[\[([^\]]+)\]\]/);
  const match3 = line.match(/^-\s*\[\[([^\]]+)\]\]\s*\(([^)]+)\)/);
  const match4 = line.match(/^-\s*([^:]+):\s*(.+)$/);
  
  if (match1) {
    // Handle format 1
  } else if (match2) {
    // Handle format 2
  }
  // ... etc
}
```

**Marked Implementation:**
```typescript
import { marked } from 'marked';

// Get the Related section
const tokens = marked.lexer(content);
const relatedSection = findSection(tokens, 'Related');

if (relatedSection && relatedSection.type === 'list') {
  for (const item of relatedSection.items) {
    const itemText = item.text; // Clean text without list marker
    
    // Now parse domain-specific formats (wiki-links, types)
    // These patterns are Obsidian-specific, not standard markdown
    const match1 = itemText.match(/^(\w+)\s+\[\[([^\]]+)\]\]/);
    const match2 = itemText.match(/^([^:]+):\s*\[\[([^\]]+)\]\]/);
    // ... etc
  }
}
```

**Benefits:**
- List marker already stripped by marked
- No manual splitting on newlines
- Automatic whitespace normalization
- Focus on domain logic (wiki-links), not markdown syntax

---

## Conclusion

The migration to the `marked` library offers significant benefits in code reduction, maintainability, and standards compliance. The analysis identifies approximately **300-450 lines of code** that can be simplified or removed, with a focus on heading detection, section extraction, and list parsing.

The key recommendation is a **gradual, phased migration** that:
1. Starts with high-value refactorings (section extraction)
2. Maintains backward compatibility
3. Clearly separates markdown parsing from domain logic
4. Consolidates repeated constants and patterns

This approach minimizes risk while delivering tangible improvements in code quality and maintainability.
